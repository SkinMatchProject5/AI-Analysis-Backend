#!/usr/bin/env python3
"""
AI-Analysis-Backend ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
ì‹¤ì œ API í˜¸ì¶œ ì‹œê°„ì„ ì¸¡ì •í•˜ì—¬ ë³‘ëª©ì§€ì ì„ ì°¾ìŠµë‹ˆë‹¤.
"""

import asyncio
import time
import httpx
import json
import sys
import os
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app.core.config import settings

class PerformanceTester:
    def __init__(self):
        self.runpod_headers = {
            "Authorization": f"Bearer {settings.RUNPOD_API_KEY}",
            "Content-Type": "application/json"
        }
        
        self.openai_headers = {
            "Authorization": f"Bearer {settings.OPENAI_API_KEY}",
            "Content-Type": "application/json"
        }

    async def test_runpod_text_diagnosis(self) -> Dict[str, Any]:
        """RunPod í…ìŠ¤íŠ¸ ì§„ë‹¨ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("ğŸ” RunPod í…ìŠ¤íŠ¸ ì§„ë‹¨ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        payload = {
            "model": settings.RUNPOD_MODEL_NAME,
            "messages": [
                {
                    "role": "system",
                    "content": """ë„ˆëŠ” í”¼ë¶€ ë³‘ë³€ì„ ì§„ë‹¨í•˜ëŠ” ì „ë¬¸ AIì´ë‹¤. ë‹¤ìŒì€ ë„¤ê°€ ì§„ë‹¨í•  ìˆ˜ ìˆëŠ” í”¼ë¶€ ë³‘ë³€ ëª©ë¡ì´ë©°, ê° ë³‘ë³€ì˜ ì„ìƒì  íŠ¹ì§•ì€ ì•„ë˜ì™€ ê°™ë‹¤. í™˜ìì—ê²Œ ë‚˜íƒ€ë‚œ ë³‘ë³€ì˜ ì´ë¯¸ì§€ì™€ ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ì§ˆë³‘ì„ í•˜ë‚˜ ì„ íƒí•˜ì—¬ ì§„ë‹¨í•˜ë¼.

0: ê´‘ì„ ê°í™”ì¦, 1: ê¸°ì €ì„¸í¬ì•”, 2: ë©œë¼ë‹Œì„¸í¬ëª¨ë°˜, 3: ë³´ì›¬ë³‘, 4: ë¹„ë¦½ì¢…,
5: ì‚¬ë§ˆê·€, 6: ì•…ì„±í‘ìƒ‰ì¢…, 7: ì§€ë£¨ê°í™”ì¦, 8: í¸í‰ì„¸í¬ì•”, 9: í‘œí”¼ë‚­ì¢…,
10: í”¼ë¶€ì„¬ìœ ì¢…, 11: í”¼ì§€ìƒ˜ì¦ì‹ì¦, 12: í˜ˆê´€ì¢…, 13: í™”ë† ìœ¡ì•„ì¢…, 14: í‘ìƒ‰ì 

<root><label id_code="{ì½”ë“œ}" score="{ì ìˆ˜}">{ì§„ë‹¨ëª…}</label><summary>{ì§„ë‹¨ì†Œê²¬}</summary><similar_labels><similar_label id_code="{ì½”ë“œ}" score="{ì ìˆ˜}">{ìœ ì‚¬ì§ˆë³‘ëª…}</similar_label></similar_labels></root>"""
                },
                {
                    "role": "user", 
                    "content": "ì–¼êµ´ì— ë¶‰ì€ìƒ‰ ê°ì§ˆì„± ë°˜ì ì´ ìˆìŠµë‹ˆë‹¤. í¬ê¸°ëŠ” ì•½ 5mmì´ê³  ê²½ê³„ê°€ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤. 70ì„¸ ë†ë¶€ì´ë©° í‰ì†Œ ì•¼ì™¸í™œë™ì„ ë§ì´ í•©ë‹ˆë‹¤."
                }
            ],
            "max_tokens": 800,
            "temperature": 0.3,
        }
        
        start_time = time.time()
        
        try:
            timeout = httpx.Timeout(120.0)  # 2ë¶„ íƒ€ì„ì•„ì›ƒ
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.post(
                    f"{settings.RUNPOD_BASE_URL}/chat/completions",
                    json=payload,
                    headers=self.runpod_headers
                )
                
                end_time = time.time()
                elapsed = end_time - start_time
                
                if response.status_code == 200:
                    data = response.json()
                    content = data["choices"][0]["message"]["content"]
                    
                    return {
                        "status": "success",
                        "elapsed_seconds": elapsed,
                        "response_length": len(content),
                        "content": content[:200] + "..." if len(content) > 200 else content
                    }
                else:
                    return {
                        "status": "error",
                        "elapsed_seconds": elapsed,
                        "error_code": response.status_code,
                        "error_message": response.text
                    }
                    
        except Exception as e:
            end_time = time.time()
            elapsed = end_time - start_time
            return {
                "status": "exception",
                "elapsed_seconds": elapsed,
                "error": str(e)
            }

    async def test_openai_text_diagnosis(self) -> Dict[str, Any]:
        """OpenAI í…ìŠ¤íŠ¸ ì§„ë‹¨ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ë¹„êµìš©)"""
        print("ğŸ” OpenAI í…ìŠ¤íŠ¸ ì§„ë‹¨ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        payload = {
            "model": "gpt-4o-mini",
            "messages": [
                {
                    "role": "system",
                    "content": """ë„ˆëŠ” í”¼ë¶€ ë³‘ë³€ì„ ì§„ë‹¨í•˜ëŠ” ì „ë¬¸ AIì´ë‹¤. ë‹¤ìŒì€ ë„¤ê°€ ì§„ë‹¨í•  ìˆ˜ ìˆëŠ” í”¼ë¶€ ë³‘ë³€ ëª©ë¡ì´ë©°, ê° ë³‘ë³€ì˜ ì„ìƒì  íŠ¹ì§•ì€ ì•„ë˜ì™€ ê°™ë‹¤. í™˜ìì—ê²Œ ë‚˜íƒ€ë‚œ ë³‘ë³€ì˜ ì´ë¯¸ì§€ì™€ ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ì§ˆë³‘ì„ í•˜ë‚˜ ì„ íƒí•˜ì—¬ ì§„ë‹¨í•˜ë¼.

0: ê´‘ì„ ê°í™”ì¦, 1: ê¸°ì €ì„¸í¬ì•”, 2: ë©œë¼ë‹Œì„¸í¬ëª¨ë°˜, 3: ë³´ì›¬ë³‘, 4: ë¹„ë¦½ì¢…,
5: ì‚¬ë§ˆê·€, 6: ì•…ì„±í‘ìƒ‰ì¢…, 7: ì§€ë£¨ê°í™”ì¦, 8: í¸í‰ì„¸í¬ì•”, 9: í‘œí”¼ë‚­ì¢…,
10: í”¼ë¶€ì„¬ìœ ì¢…, 11: í”¼ì§€ìƒ˜ì¦ì‹ì¦, 12: í˜ˆê´€ì¢…, 13: í™”ë† ìœ¡ì•„ì¢…, 14: í‘ìƒ‰ì 

<root><label id_code="{ì½”ë“œ}" score="{ì ìˆ˜}">{ì§„ë‹¨ëª…}</label><summary>{ì§„ë‹¨ì†Œê²¬}</summary><similar_labels><similar_label id_code="{ì½”ë“œ}" score="{ì ìˆ˜}">{ìœ ì‚¬ì§ˆë³‘ëª…}</similar_label></similar_labels></root>"""
                },
                {
                    "role": "user", 
                    "content": "ì–¼êµ´ì— ë¶‰ì€ìƒ‰ ê°ì§ˆì„± ë°˜ì ì´ ìˆìŠµë‹ˆë‹¤. í¬ê¸°ëŠ” ì•½ 5mmì´ê³  ê²½ê³„ê°€ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤. 70ì„¸ ë†ë¶€ì´ë©° í‰ì†Œ ì•¼ì™¸í™œë™ì„ ë§ì´ í•©ë‹ˆë‹¤."
                }
            ],
            "max_tokens": 800,
            "temperature": 0.3,
        }
        
        start_time = time.time()
        
        try:
            timeout = httpx.Timeout(60.0)
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    json=payload,
                    headers=self.openai_headers
                )
                
                end_time = time.time()
                elapsed = end_time - start_time
                
                if response.status_code == 200:
                    data = response.json()
                    content = data["choices"][0]["message"]["content"]
                    
                    return {
                        "status": "success",
                        "elapsed_seconds": elapsed,
                        "response_length": len(content),
                        "content": content[:200] + "..." if len(content) > 200 else content
                    }
                else:
                    return {
                        "status": "error",
                        "elapsed_seconds": elapsed,
                        "error_code": response.status_code,
                        "error_message": response.text
                    }
                    
        except Exception as e:
            end_time = time.time()
            elapsed = end_time - start_time
            return {
                "status": "exception",
                "elapsed_seconds": elapsed,
                "error": str(e)
            }

    async def test_multiple_runs(self, provider: str, runs: int = 3):
        """ì—¬ëŸ¬ ë²ˆ í…ŒìŠ¤íŠ¸í•˜ì—¬ í‰ê·  ì„±ëŠ¥ ì¸¡ì •"""
        print(f"\nğŸ”„ {provider} ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ({runs}íšŒ)")
        
        results = []
        total_time = 0
        successful_runs = 0
        
        for i in range(runs):
            print(f"  ğŸ“Š í…ŒìŠ¤íŠ¸ {i+1}/{runs} ì§„í–‰ ì¤‘...")
            
            if provider.lower() == "runpod":
                result = await self.test_runpod_text_diagnosis()
            elif provider.lower() == "openai":
                result = await self.test_openai_text_diagnosis()
            else:
                print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” í”„ë¡œë°”ì´ë”: {provider}")
                return
            
            results.append(result)
            
            if result["status"] == "success":
                successful_runs += 1
                total_time += result["elapsed_seconds"]
                print(f"    âœ… ì„±ê³µ: {result['elapsed_seconds']:.2f}ì´ˆ")
            else:
                print(f"    âŒ ì‹¤íŒ¨: {result.get('error', result.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'))}")
            
            # ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ì „ ì ì‹œ ëŒ€ê¸°
            if i < runs - 1:
                await asyncio.sleep(2)
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“ˆ {provider} ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"  ì„±ê³µë¥ : {successful_runs}/{runs} ({successful_runs/runs*100:.1f}%)")
        
        if successful_runs > 0:
            avg_time = total_time / successful_runs
            print(f"  í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            
            # ê°œë³„ ê²°ê³¼ ì¶œë ¥
            print(f"\n  ğŸ“‹ ê°œë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
            for i, result in enumerate(results, 1):
                if result["status"] == "success":
                    print(f"    {i}: {result['elapsed_seconds']:.2f}ì´ˆ")
                else:
                    print(f"    {i}: ì‹¤íŒ¨ ({result.get('error', result.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'))})")
        
        return results

    async def run_comparison_test(self):
        """RunPod vs OpenAI ë¹„êµ í…ŒìŠ¤íŠ¸"""
        print("ğŸš€ AI-Analysis-Backend ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*60)
        
        # ì„¤ì • ì •ë³´ ì¶œë ¥
        print(f"ğŸ”§ í˜„ì¬ ì„¤ì •:")
        print(f"  RunPod Base URL: {settings.RUNPOD_BASE_URL}")
        print(f"  RunPod Model: {settings.RUNPOD_MODEL_NAME}")
        print(f"  OpenAI API í‚¤: {'ì„¤ì •ë¨' if settings.OPENAI_API_KEY else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
        print(f"  RunPod API í‚¤: {'ì„¤ì •ë¨' if settings.RUNPOD_API_KEY else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
        
        # RunPod í…ŒìŠ¤íŠ¸
        runpod_results = await self.test_multiple_runs("runpod", 3)
        
        # OpenAI í…ŒìŠ¤íŠ¸ (ë¹„êµìš©)
        if settings.OPENAI_API_KEY:
            await asyncio.sleep(3)  # ì ì‹œ ëŒ€ê¸°
            openai_results = await self.test_multiple_runs("openai", 3)
        else:
            print("\nâš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ OpenAI í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            openai_results = []
        
        # ë¹„êµ ê²°ê³¼ ì¶œë ¥
        print("\nğŸ† ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
        print("="*60)
        
        runpod_success = [r for r in runpod_results if r["status"] == "success"]
        openai_success = [r for r in openai_results if r["status"] == "success"]
        
        if runpod_success:
            runpod_avg = sum(r["elapsed_seconds"] for r in runpod_success) / len(runpod_success)
            print(f"RunPod í‰ê· : {runpod_avg:.2f}ì´ˆ ({len(runpod_success)}/{len(runpod_results)} ì„±ê³µ)")
        
        if openai_success:
            openai_avg = sum(r["elapsed_seconds"] for r in openai_success) / len(openai_success)
            print(f"OpenAI í‰ê· : {openai_avg:.2f}ì´ˆ ({len(openai_success)}/{len(openai_results)} ì„±ê³µ)")
        
        # ê¶Œì¥ì‚¬í•­
        print("\nğŸ’¡ ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­:")
        if runpod_success and any(r["elapsed_seconds"] > 60 for r in runpod_success):
            print("  âš ï¸ RunPod ì‘ë‹µ ì‹œê°„ì´ 60ì´ˆë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")
            print("     - ëª¨ë¸ ìµœì í™” í•„ìš”")
            print("     - ì„œë²„ ìœ„ì¹˜ í™•ì¸")
            print("     - ìš”ì²­ í¬ê¸° ì¤„ì´ê¸° (max_tokens, temperature ì¡°ì •)")
        
        if runpod_success and openai_success:
            runpod_avg = sum(r["elapsed_seconds"] for r in runpod_success) / len(runpod_success)
            openai_avg = sum(r["elapsed_seconds"] for r in openai_success) / len(openai_success)
            
            if runpod_avg > openai_avg * 2:
                print("     - RunPodì´ OpenAIë³´ë‹¤ 2ë°° ì´ìƒ ëŠë¦¼")
                print("     - OpenAIë¡œ í”„ë¡œë°”ì´ë” ë³€ê²½ ê³ ë ¤")
            elif openai_avg > runpod_avg * 2:
                print("     - OpenAIê°€ RunPodë³´ë‹¤ 2ë°° ì´ìƒ ëŠë¦¼")
                print("     - RunPod ì‚¬ìš© ìœ ì§€ ê¶Œì¥")

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    tester = PerformanceTester()
    await tester.run_comparison_test()

if __name__ == "__main__":
    asyncio.run(main())
